╔══════════════════════════════════════════════════════════════════════════════╗
║           AI-POWERED TEST CASE GENERATOR - SYSTEM ARCHITECTURE               ║
║                    Azure OpenAI + CrewAI + RAG                               ║
╚══════════════════════════════════════════════════════════════════════════════╝

┌──────────────────────────────────────────────────────────────────────────────┐
│                           USER INPUT LAYER                                    │
│  ┌────────────────────────────────────────────────────────────────────────┐  │
│  │  User enters feature description / requirement / test scenario         │  │
│  │  Examples:                                                              │  │
│  │    - "User authentication with OAuth2"                                 │  │
│  │    - "API endpoint /users/create with validation"                      │  │
│  │    - "Payment processing workflow"                                     │  │
│  └────────────────────────────────────────────────────────────────────────┘  │
└─────────────────────────────────────┬────────────────────────────────────────┘
                                      │
                                      ▼
┌──────────────────────────────────────────────────────────────────────────────┐
│                   LAYER 1: PROMPT PREPROCESSING                              │
│  ┌────────────────────────────────────────────────────────────────────────┐  │
│  │  Component: PromptPreprocessor (src/utils/prompt_preprocessor.py)     │  │
│  │  ┌──────────────────────────────────────────────────────────────────┐ │  │
│  │  │  1. Intent Extraction                                             │ │  │
│  │  │     → Classify: feature/workflow/API/configuration/bug            │ │  │
│  │  │                                                                    │ │  │
│  │  │  2. Entity Identification                                          │ │  │
│  │  │     → Extract: keywords, components, APIs, services              │ │  │
│  │  │                                                                    │ │  │
│  │  │  3. Multi-Query Generation                                         │ │  │
│  │  │     → Generate 3-5 optimized search queries                       │ │  │
│  │  │     → Examples:                                                    │ │  │
│  │  │       • Original: "user authentication OAuth2"                    │ │  │
│  │  │       • Query 1: "user authentication OAuth2 functionality"      │ │  │
│  │  │       • Query 2: "OAuth2 implementation details"                  │ │  │
│  │  │       • Query 3: "authentication security authorization"          │ │  │
│  │  └──────────────────────────────────────────────────────────────────┘ │  │
│  │                                                                         │  │
│  │  Powered by: Azure OpenAI GPT-4.1-nano (temperature=0.3)              │  │
│  │  Output: Intent, Keywords, Entities, Search Queries                    │  │
│  └────────────────────────────────────────────────────────────────────────┘  │
└─────────────────────────────────────┬────────────────────────────────────────┘
                                      │
                                      ▼
┌──────────────────────────────────────────────────────────────────────────────┐
│                  LAYER 2: RAG RETRIEVAL (Enhanced)                           │
│  ┌────────────────────────────────────────────────────────────────────────┐  │
│  │  Component: EnhancedRetrieval (src/vector_db/enhanced_retrieval.py)   │  │
│  │  ┌──────────────────────────────────────────────────────────────────┐ │  │
│  │  │  Step 1: Multi-Query Execution                                    │ │  │
│  │  │  ┌─────────────────────────────────────────────────────────────┐ │ │  │
│  │  │  │  For each query (3-5 queries):                              │ │ │  │
│  │  │  │    → Hybrid Search (70% semantic + 30% keyword BM25)        │ │ │  │
│  │  │  │    → Retrieve top-k chunks (k=5)                            │ │ │  │
│  │  │  │    → Track source query for ranking                         │ │ │  │
│  │  │  └─────────────────────────────────────────────────────────────┘ │ │  │
│  │  │                                                                    │ │  │
│  │  │  Step 2: Result Aggregation                                       │ │  │
│  │  │  ┌─────────────────────────────────────────────────────────────┐ │ │  │
│  │  │  │  → Deduplicate by chunk_id                                  │ │ │  │
│  │  │  │  → Rerank by relevance score                                │ │ │  │
│  │  │  │  → Return top 10-20 unique chunks                           │ │ │  │
│  │  │  └─────────────────────────────────────────────────────────────┘ │ │  │
│  │  │                                                                    │ │  │
│  │  │  Step 3: Context Expansion (Optional)                             │ │  │
│  │  │  ┌─────────────────────────────────────────────────────────────┐ │ │  │
│  │  │  │  → Include neighboring chunks from same document            │ │ │  │
│  │  │  │  → Expand window by ±1 chunk for better context            │ │ │  │
│  │  │  └─────────────────────────────────────────────────────────────┘ │ │  │
│  │  │                                                                    │ │  │
│  │  │  Step 4: Adaptive Retrieval                                       │ │  │
│  │  │  ┌─────────────────────────────────────────────────────────────┐ │ │  │
│  │  │  │  If results < min_threshold:                                │ │ │  │
│  │  │  │    → Try semantic-only search                               │ │ │  │
│  │  │  │    → Merge with existing results                            │ │ │  │
│  │  │  └─────────────────────────────────────────────────────────────┘ │ │  │
│  │  └──────────────────────────────────────────────────────────────────┘ │  │
│  │                                                                         │  │
│  │  Vector DB: FAISS (Facebook AI Similarity Search)                      │  │
│  │  Embeddings: all-MiniLM-L6-v2 (384 dimensions)                         │  │
│  │  Output: 10-20 most relevant document chunks with metadata             │  │
│  └────────────────────────────────────────────────────────────────────────┘  │
└─────────────────────────────────────┬────────────────────────────────────────┘
                                      │
                                      ▼
┌──────────────────────────────────────────────────────────────────────────────┐
│                    LAYER 2.5: CONTEXT ENRICHMENT                             │
│  ┌────────────────────────────────────────────────────────────────────────┐  │
│  │  Component: PromptPreprocessor.enrich_context()                        │  │
│  │  ┌──────────────────────────────────────────────────────────────────┐ │  │
│  │  │  Combine:                                                         │ │  │
│  │  │    1. Original user prompt                                        │ │  │
│  │  │    2. Retrieved RAG context chunks                                │ │  │
│  │  │    3. Source document metadata                                    │ │  │
│  │  │                                                                    │ │  │
│  │  │  Format:                                                           │ │  │
│  │  │    === USER REQUEST ===                                           │ │  │
│  │  │    [user prompt]                                                  │ │  │
│  │  │                                                                    │ │  │
│  │  │    === RETRIEVED DOCUMENTATION CONTEXT ===                        │ │  │
│  │  │    --- Context 1 (Source: admin_guide.pdf) ---                   │ │  │
│  │  │    [chunk text]                                                   │ │  │
│  │  │    --- Context 2 (Source: api_docs.pdf) ---                      │ │  │
│  │  │    [chunk text]                                                   │ │  │
│  │  │    ...                                                             │ │  │
│  │  └──────────────────────────────────────────────────────────────────┘ │  │
│  │                                                                         │  │
│  │  Output: Enriched context (typically 10,000-15,000 characters)         │  │
│  └────────────────────────────────────────────────────────────────────────┘  │
└─────────────────────────────────────┬────────────────────────────────────────┘
                                      │
                                      ▼
┌──────────────────────────────────────────────────────────────────────────────┐
║               LAYER 3: CREWAI MULTI-AGENT ORCHESTRATION                      ║
│  ┌────────────────────────────────────────────────────────────────────────┐  │
│  │  Component: CrewOrchestrator (src/orchestration/crew_orchestrator.py) │  │
│  └────────────────────────────────────────────────────────────────────────┘  │
│                                                                               │
│  ╔═══════════════════════════════════════════════════════════════════════╗  │
│  ║  PHASE 1: TEST PLANNING                                               ║  │
│  ╚═══════════════════════════════════════════════════════════════════════╝  │
│  ┌────────────────────────────────────────────────────────────────────────┐  │
│  │  Agent: Task Planner (src/agents/task_planner_agent.py)               │  │
│  │  Role: Senior QA Test Architect                                        │  │
│  │  ┌──────────────────────────────────────────────────────────────────┐ │  │
│  │  │  Input: Enriched context (user prompt + RAG results)             │ │  │
│  │  │                                                                    │ │  │
│  │  │  Analysis:                                                         │ │  │
│  │  │    • Feature overview (what needs testing)                        │ │  │
│  │  │    • Test objectives (what we're validating)                      │ │  │
│  │  │    • Coverage areas:                                              │ │  │
│  │  │        ✓ Positive scenarios (happy path)                         │ │  │
│  │  │        ✓ Negative scenarios (error cases)                        │ │  │
│  │  │        ✓ Boundary conditions (edge cases)                        │ │  │
│  │  │        ✓ Integration points (component interactions)             │ │  │
│  │  │        ✓ Security considerations (auth, validation)              │ │  │
│  │  │        ✓ Performance requirements (load, stress)                 │ │  │
│  │  │    • Risk areas (high-risk functionality)                         │ │  │
│  │  │    • Prerequisites and dependencies                               │ │  │
│  │  │    • Test data requirements                                       │ │  │
│  │  │                                                                    │ │  │
│  │  │  Output: Comprehensive test planning strategy                     │ │  │
│  │  └──────────────────────────────────────────────────────────────────┘ │  │
│  │  Powered by: Azure OpenAI GPT-4.1-nano (temperature=0.7)              │  │
│  └────────────────────────────────────────────────────────────────────────┘  │
│                                │                                              │
│                                ▼                                              │
│  ╔═══════════════════════════════════════════════════════════════════════╗  │
│  ║  PHASE 2: TEST CASE GENERATION                                        ║  │
│  ╚═══════════════════════════════════════════════════════════════════════╝  │
│  ┌────────────────────────────────────────────────────────────────────────┐  │
│  │  Agent: Test Generator (src/agents/test_generator_agent.py)           │  │
│  │  Role: Expert Test Case Designer                                       │  │
│  │  ┌──────────────────────────────────────────────────────────────────┐ │  │
│  │  │  Input: Test plan + Enriched context                              │ │  │
│  │  │                                                                    │ │  │
│  │  │  Generation (minimum 10 test cases):                              │ │  │
│  │  │    For EACH test case:                                            │ │  │
│  │  │      • Test ID: Unique identifier (TC_001, TC_002, ...)          │ │  │
│  │  │      • Test Title: Clear, descriptive title                      │ │  │
│  │  │      • Category: positive/negative/boundary/integration/etc.     │ │  │
│  │  │      • Priority: Critical/High/Medium/Low                        │ │  │
│  │  │      • Description: What this test validates                     │ │  │
│  │  │      • Prerequisites: Setup required                              │ │  │
│  │  │      • Test Data: Specific data needed                           │ │  │
│  │  │      • Test Steps: Detailed numbered steps                       │ │  │
│  │  │      • Expected Results: Precise outcome                         │ │  │
│  │  │      • Postconditions: State after execution                     │ │  │
│  │  │                                                                    │ │  │
│  │  │  Coverage Requirements:                                            │ │  │
│  │  │    ✓ Positive (30-40%): Happy path scenarios                     │ │  │
│  │  │    ✓ Negative (25-35%): Error handling                           │ │  │
│  │  │    ✓ Boundary (15-20%): Edge cases                               │ │  │
│  │  │    ✓ Integration (10-15%): Component interactions                │ │  │
│  │  │    ✓ Security (5-10%): Auth, authorization, injection            │ │  │
│  │  │    ✓ Performance (5-10%): Load, stress                           │ │  │
│  │  │                                                                    │ │  │
│  │  │  Output: 10-20 comprehensive test cases                           │ │  │
│  │  └──────────────────────────────────────────────────────────────────┘ │  │
│  │  Powered by: Azure OpenAI GPT-4.1-nano (temperature=0.7)              │  │
│  └────────────────────────────────────────────────────────────────────────┘  │
│                                │                                              │
│                                ▼                                              │
│  ╔═══════════════════════════════════════════════════════════════════════╗  │
│  ║  PHASE 3: VALIDATION & QUALITY ASSURANCE                              ║  │
│  ╚═══════════════════════════════════════════════════════════════════════╝  │
│  ┌────────────────────────────────────────────────────────────────────────┐  │
│  │  Agent: Validation (src/agents/validation_agent.py)                   │  │
│  │  Role: Senior QA Quality Auditor                                       │  │
│  │  ┌──────────────────────────────────────────────────────────────────┐ │  │
│  │  │  Input: Generated test cases + Test plan                          │ │  │
│  │  │                                                                    │ │  │
│  │  │  Validation Checks:                                                │ │  │
│  │  │    1. Coverage Analysis:                                          │ │  │
│  │  │       • Positive scenarios: X/X complete                         │ │  │
│  │  │       • Negative scenarios: X/X complete                         │ │  │
│  │  │       • Boundary scenarios: X/X complete                         │ │  │
│  │  │       • Integration scenarios: X/X complete                      │ │  │
│  │  │       • Security scenarios: X/X complete                         │ │  │
│  │  │       • Performance scenarios: X/X complete                      │ │  │
│  │  │                                                                    │ │  │
│  │  │    2. Quality Check:                                              │ │  │
│  │  │       ✓ All fields present and complete?                         │ │  │
│  │  │       ✓ Test steps clear and executable?                         │ │  │
│  │  │       ✓ Expected results precise?                                │ │  │
│  │  │       ✓ Test data specified?                                     │ │  │
│  │  │       ✓ Independent and repeatable?                              │ │  │
│  │  │                                                                    │ │  │
│  │  │    3. Gap Analysis:                                               │ │  │
│  │  │       • Missing scenarios                                         │ │  │
│  │  │       • Ambiguous test cases                                      │ │  │
│  │  │       • Edge cases not covered                                    │ │  │
│  │  │                                                                    │ │  │
│  │  │    4. Final Verdict:                                              │ │  │
│  │  │       • Quality score (1-10)                                      │ │  │
│  │  │       • Ready for execution? (Yes/No/With modifications)         │ │  │
│  │  │       • Recommendations                                           │ │  │
│  │  │                                                                    │ │  │
│  │  │  Output: Validation report with quality assessment                │ │  │
│  │  └──────────────────────────────────────────────────────────────────┘ │  │
│  │  Powered by: Azure OpenAI GPT-4.1-nano (temperature=0.7)              │  │
│  └────────────────────────────────────────────────────────────────────────┘  │
│                                                                               │
│  ┌────────────────────────────────────────────────────────────────────────┐  │
│  │  Optional: Iterative Refinement (MAX_ITERATIONS=3)                    │  │
│  │  ┌──────────────────────────────────────────────────────────────────┐ │  │
│  │  │  If quality score < 10:                                           │ │  │
│  │  │    → Add validation feedback to context                          │ │  │
│  │  │    → Re-run generation phase                                     │ │  │
│  │  │    → Repeat validation                                            │ │  │
│  │  │    → Max 3 iterations                                             │ │  │
│  │  └──────────────────────────────────────────────────────────────────┘ │  │
│  └────────────────────────────────────────────────────────────────────────┘  │
└─────────────────────────────────────┬────────────────────────────────────────┘
                                      │
                                      ▼
┌──────────────────────────────────────────────────────────────────────────────┐
│                 LAYER 4: OUTPUT FORMATTING & EXPORT                          │
│  ┌────────────────────────────────────────────────────────────────────────┐  │
│  │  Component: TestCaseFormatter (src/utils/output_formatter.py)         │  │
│  │  ┌──────────────────────────────────────────────────────────────────┐ │  │
│  │  │  Parse: Extract structured test case data from text               │ │  │
│  │  │  ┌────────────────────────────────────────────────────────────┐  │ │  │
│  │  │  │  • Split by test case ID pattern                           │  │ │  │
│  │  │  │  • Extract all fields (ID, title, category, etc.)          │  │ │  │
│  │  │  │  • Create structured dictionary for each test              │  │ │  │
│  │  │  └────────────────────────────────────────────────────────────┘  │ │  │
│  │  │                                                                    │ │  │
│  │  │  Export Formats:                                                   │ │  │
│  │  │  ┌────────────────────────────────────────────────────────────┐  │ │  │
│  │  │  │  1. JSON (test_cases_TIMESTAMP.json)                       │  │ │  │
│  │  │  │     • Structured data                                       │  │ │  │
│  │  │  │     • For automation/CI/CD                                  │  │ │  │
│  │  │  │     • Easy parsing                                          │  │ │  │
│  │  │  │                                                              │  │ │  │
│  │  │  │  2. Markdown (test_cases_TIMESTAMP.md)                     │  │ │  │
│  │  │  │     • Human-readable                                        │  │ │  │
│  │  │  │     • For documentation                                     │  │ │  │
│  │  │  │     • Easy sharing/review                                   │  │ │  │
│  │  │  │                                                              │  │ │  │
│  │  │  │  3. Excel (test_cases_TIMESTAMP.xlsx)                      │  │ │  │
│  │  │  │     • Spreadsheet format                                    │  │ │  │
│  │  │  │     • For manual review                                     │  │ │  │
│  │  │  │     • Import to Jira/TestRail/Zephyr                       │  │ │  │
│  │  │  └────────────────────────────────────────────────────────────┘  │ │  │
│  │  └──────────────────────────────────────────────────────────────────┘ │  │
│  │                                                                         │  │
│  │  Output Location: data/test_cases/                                     │  │
│  └────────────────────────────────────────────────────────────────────────┘  │
└─────────────────────────────────────┬────────────────────────────────────────┘
                                      │
                                      ▼
┌──────────────────────────────────────────────────────────────────────────────┐
│                           FINAL OUTPUT                                        │
│  ┌────────────────────────────────────────────────────────────────────────┐  │
│  │  ✓ Comprehensive Test Plan                                             │  │
│  │  ✓ 10-20 Detailed Test Cases (all coverage types)                      │  │
│  │  ✓ Validation Report with Quality Score                                │  │
│  │  ✓ 3 Output Files (JSON, Markdown, Excel)                              │  │
│  │  ✓ Metadata (sources, RAG results, generation time)                    │  │
│  └────────────────────────────────────────────────────────────────────────┘  │
└──────────────────────────────────────────────────────────────────────────────┘

╔══════════════════════════════════════════════════════════════════════════════╗
║                           TECHNOLOGY STACK                                    ║
╚══════════════════════════════════════════════════════════════════════════════╝

┌─────────────────────────┬───────────────────────────────────────────────────┐
│ Component               │ Technology                                        │
├─────────────────────────┼───────────────────────────────────────────────────┤
│ LLM                     │ Azure OpenAI GPT-4.1-nano                        │
│ Multi-Agent Framework   │ CrewAI 0.11+                                     │
│ LLM Orchestration       │ LangChain 0.1+                                    │
│ Vector Database         │ FAISS (Facebook AI Similarity Search)            │
│ Embeddings              │ all-MiniLM-L6-v2 (384 dimensions)                │
│ Document Processing     │ pdfplumber, pypdfium2                             │
│ Search Algorithm        │ Hybrid (Semantic + BM25)                          │
│ Output Formats          │ JSON, Markdown, Excel (openpyxl)                  │
│ Programming Language    │ Python 3.10-3.13                                  │
└─────────────────────────┴───────────────────────────────────────────────────┘

╔══════════════════════════════════════════════════════════════════════════════╗
║                         PERFORMANCE METRICS                                   ║
╚══════════════════════════════════════════════════════════════════════════════╝

┌─────────────────────────┬───────────────────────────────────────────────────┐
│ Metric                  │ Value                                             │
├─────────────────────────┼───────────────────────────────────────────────────┤
│ Prompt Preprocessing    │ 2-3 seconds                                       │
│ RAG Retrieval           │ 2-5 seconds                                       │
│ Agent Orchestration     │ 30-60 seconds                                     │
│ Total Generation Time   │ 35-70 seconds per feature                         │
│ Test Cases Generated    │ 10-20 per feature                                 │
│ Test Coverage           │ 90-95%                                            │
│ Quality Score           │ 8-10/10 (with iteration)                          │
│ Cost per Feature        │ ~$0.26 (Azure OpenAI tokens)                      │
│ Productivity Gain       │ 100-200x faster than manual                       │
└─────────────────────────┴───────────────────────────────────────────────────┘

═══════════════════════════════════════════════════════════════════════════════
                           END OF ARCHITECTURE
═══════════════════════════════════════════════════════════════════════════════
