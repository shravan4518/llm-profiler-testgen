# Project Structure - AI Test Case Generator

**Last Updated:** 2025-11-29
**Status:** Production-Ready

---

## ğŸ“ **Root Directory Structure**

```
POC/
â”œâ”€â”€ config.py                    # Central configuration file (Azure OpenAI, paths, settings)
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ README.md                    # Main project documentation
â”œâ”€â”€ PROJECT_STRUCTURE.md         # This file - project organization guide
â”‚
â”œâ”€â”€ run_testgen_simple.py        # â­ MAIN ENTRY POINT - Simplified test generator
â”œâ”€â”€ run_testgen.py               # Multi-agent version (requires CrewAI)
â”‚
â”œâ”€â”€ venv_313/                    # Active Python virtual environment (Python 3.13)
â”‚
â”œâ”€â”€ src/                         # Source code (core system)
â”œâ”€â”€ data/                        # Data storage (docs, indexes, outputs)
â”œâ”€â”€ docs/                        # Documentation
â””â”€â”€ scripts/                     # Utility scripts and tests
```

---

## ğŸ¯ **Quick Start**

### **Generate Test Cases (Recommended)**

```bash
# 1. Activate virtual environment
venv_313\Scripts\activate

# 2. Run simplified test generator
python run_testgen_simple.py
```

### **Ingest Documents**

```bash
# Add documents to data/docs/ then run:
python src/main_enterprise.py
# Choose [I] Ingest documents
```

---

## ğŸ“‚ **Detailed Directory Structure**

### **1. `/src` - Source Code**

```
src/
â”œâ”€â”€ agents/                      # CrewAI agents (for multi-agent version)
â”‚   â”œâ”€â”€ task_planner_agent.py
â”‚   â”œâ”€â”€ test_generator_agent.py
â”‚   â””â”€â”€ validation_agent.py
â”‚
â”œâ”€â”€ document_processing/         # Document loaders and processing
â”‚   â”œâ”€â”€ loaders.py               # PDF, TXT, DOCX loaders
â”‚   â””â”€â”€ image_processor.py       # Multimodal image processing
â”‚
â”œâ”€â”€ orchestration/               # Multi-agent orchestration
â”‚   â””â”€â”€ crew_orchestrator.py    # CrewAI workflow manager
â”‚
â”œâ”€â”€ utils/                       # Utility modules
â”‚   â”œâ”€â”€ azure_llm.py             # Azure OpenAI integration
â”‚   â”œâ”€â”€ logger.py                # Logging configuration
â”‚   â”œâ”€â”€ output_formatter.py      # JSON/Markdown/Excel formatters
â”‚   â””â”€â”€ prompt_preprocessor.py   # Prompt analysis and optimization
â”‚
â”œâ”€â”€ vector_db/                   # Vector database and RAG
â”‚   â”œâ”€â”€ vector_store.py          # FAISS vector store
â”‚   â”œâ”€â”€ search_engine.py         # Hybrid search (semantic + BM25)
â”‚   â”œâ”€â”€ enhanced_retrieval.py    # Multi-query adaptive retrieval
â”‚   â””â”€â”€ embedding_models.py      # Sentence-transformers models
â”‚
â”œâ”€â”€ main_enterprise.py           # RAG system (ingestion, search, Q&A)
â”œâ”€â”€ simple_testgen.py            # â­ Simplified test case generator
â””â”€â”€ testcase_generator.py        # Multi-agent test case generator
```

**Key Files:**
- **`simple_testgen.py`** - Fast, single-call test generation (recommended)
- **`testcase_generator.py`** - Multi-agent version (slower, more sophisticated)
- **`main_enterprise.py`** - Document ingestion and RAG Q&A
- **`azure_llm.py`** - Azure OpenAI wrapper
- **`output_formatter.py`** - Formats test cases to JSON/Markdown/Excel

---

### **2. `/data` - Data Storage**

```
data/
â”œâ”€â”€ docs/                        # Source documents for ingestion
â”‚   â”œâ”€â”€ .gitkeep
â”‚   â”œâ”€â”€ PP-Profiler Design-241125-070351.pdf
â”‚   â””â”€â”€ ps-pps-9.1r10.0-profiler-administration-guide.pdf
â”‚
â”œâ”€â”€ faiss_index/                 # Vector database index
â”‚   â”œâ”€â”€ faiss_index.bin          # FAISS index file
â”‚   â”œâ”€â”€ chunk_metadata.pkl       # Chunk metadata
â”‚   â””â”€â”€ document_registry.pkl    # Document registry
â”‚
â”œâ”€â”€ test_cases/                  # Generated test cases
â”‚   â”œâ”€â”€ test_cases_TIMESTAMP.json
â”‚   â”œâ”€â”€ test_cases_TIMESTAMP.md
â”‚   â””â”€â”€ test_cases_TIMESTAMP.xlsx
â”‚
â”œâ”€â”€ logs/                        # System logs
â”‚   â””â”€â”€ rag_system.log
â”‚
â””â”€â”€ archive/                     # Old LLM outputs (archived)
    â”œâ”€â”€ llm_answer_*.txt
    â””â”€â”€ search_results_*.txt
```

**Important:**
- Add your documentation files to `data/docs/`
- Generated test cases are in `data/test_cases/`
- FAISS index is in `data/faiss_index/` (auto-created on ingestion)

---

### **3. `/docs` - Documentation**

```
docs/
â”œâ”€â”€ README_TESTGEN.md            # Test generation system overview
â”œâ”€â”€ README_SIMPLE_VERSION.md     # Simplified version guide
â”œâ”€â”€ QUICKSTART_SIMPLE.md         # Quick start guide
â”œâ”€â”€ SETUP_AZURE_TESTGEN.md       # Multi-agent setup guide
â”œâ”€â”€ AI_TESTGEN_IMPLEMENTATION_SUMMARY.md  # Implementation details
â”‚
â”œâ”€â”€ guides/                      # System guides
â”‚   â”œâ”€â”€ ENTERPRISE_RAG_DOCUMENTATION.txt
â”‚   â””â”€â”€ SYSTEM_ARCHITECTURE.txt
â”‚
â””â”€â”€ archive/                     # Old/legacy documentation
    â”œâ”€â”€ CLEANUP_SUMMARY.txt
    â”œâ”€â”€ QUICK_START.txt
    â”œâ”€â”€ SEARCH_OUTPUT_GUIDE.txt
    â”œâ”€â”€ SYSTEM_SUMMARY.txt
    â”œâ”€â”€ GEMINI_FREE_TIER_FIX.txt
    â”œâ”€â”€ LLM_QA_FEATURE_GUIDE.txt
    â”œâ”€â”€ LLM_QA_TROUBLESHOOTING.txt
    â”œâ”€â”€ LLM_QA_UPDATE_SUMMARY.txt
    â””â”€â”€ MULTIMODAL_SETUP_GUIDE.txt
```

**Key Documentation:**
- **Start here:** `docs/QUICKSTART_SIMPLE.md`
- **System overview:** `docs/README_SIMPLE_VERSION.md`
- **Architecture:** `docs/guides/SYSTEM_ARCHITECTURE.txt`

---

### **4. `/scripts` - Utility Scripts**

```
scripts/
â”œâ”€â”€ tests/                       # Test and debug scripts
â”‚   â”œâ”€â”€ test_generation.py       # Automated test generation
â”‚   â”œâ”€â”€ test_parser.py           # Parser testing
â”‚   â”œâ”€â”€ test_parser_debug.py     # Parser debugging
â”‚   â”œâ”€â”€ test_regex.py            # Regex pattern testing
â”‚   â””â”€â”€ debug_output.py          # Debug LLM output
â”‚
â””â”€â”€ archive/                     # Old/archived scripts
    â””â”€â”€ api-testing.py           # Legacy API testing
```

**Usage:**
- Test scripts are for development/debugging only
- Run from project root: `python scripts/tests/test_generation.py`

---

## ğŸ”§ **Configuration**

### **Environment Variables (Recommended)**

```powershell
# Windows PowerShell
$env:AZURE_OPENAI_ENDPOINT = "https://your-resource.openai.azure.com/"
$env:AZURE_OPENAI_API_KEY = "your-api-key"
$env:AZURE_OPENAI_DEPLOYMENT = "gpt-4-1-nano"
```

### **OR Edit config.py Directly**

```python
# Lines 56-59 in config.py
AZURE_OPENAI_ENDPOINT = "https://your-resource.openai.azure.com/"
AZURE_OPENAI_API_KEY = "your-api-key"
AZURE_OPENAI_DEPLOYMENT = "gpt-4-1-nano"
AZURE_OPENAI_API_VERSION = "2024-08-01-preview"
```

---

## ğŸ“Š **Key Features**

### **1. Simplified Test Generator** (`run_testgen_simple.py`)
- âš¡ Fast: 10-15 seconds per feature
- ğŸ’° Affordable: ~$0.001 per generation
- ğŸ“‹ Comprehensive: 15-20 test cases per feature
- ğŸ“¤ Multi-format: JSON, Markdown, Excel output

### **2. RAG System** (`src/main_enterprise.py`)
- ğŸ“š Document ingestion (PDF, TXT, DOCX)
- ğŸ” Hybrid search (semantic + keyword)
- ğŸ¤– LLM-powered Q&A
- ğŸ“Š Statistics and monitoring

### **3. Multi-Agent Version** (`run_testgen.py`)
- ğŸ¤– 3 specialized agents (Planner, Generator, Validator)
- ğŸ”„ CrewAI orchestration
- â±ï¸ Slower (45-60 seconds) but more sophisticated
- ğŸ’¸ More expensive (~$0.26 per feature)

---

## ğŸš€ **Common Workflows**

### **Workflow 1: Generate Test Cases**

```bash
# 1. Activate environment
venv_313\Scripts\activate

# 2. Ensure documents are ingested (one-time)
python src/main_enterprise.py
# Choose [I] Ingest documents

# 3. Generate test cases
python run_testgen_simple.py
# Enter feature description when prompted

# 4. Find outputs in data/test_cases/
```

### **Workflow 2: Search Documentation**

```bash
# 1. Activate environment
venv_313\Scripts\activate

# 2. Run RAG system
python src/main_enterprise.py

# 3. Choose [S] Search knowledge base
# Or [Q] Ask question (LLM-powered Q&A)
```

### **Workflow 3: Add New Documents**

```bash
# 1. Copy documents to data/docs/
copy your-new-doc.pdf data\docs\

# 2. Run ingestion
python src/main_enterprise.py
# Choose [I] Ingest documents

# 3. System indexes new documents automatically
```

---

## ğŸ“ˆ **Performance Metrics**

| Metric | Simplified | Multi-Agent |
|--------|------------|-------------|
| Speed | 10-15s | 45-60s |
| Cost/feature | ~$0.001 | ~$0.26 |
| Test cases | 15-20 | 15-20 |
| Quality | â­â­â­â­â­ | â­â­â­â­â­ |
| Python version | Any | 3.10-3.13 |
| Dependencies | Minimal | CrewAI required |

---

## ğŸ” **File Locations**

### **Input Files**
- Source documents: `data/docs/`
- Configuration: `config.py`

### **Output Files**
- Test cases: `data/test_cases/test_cases_TIMESTAMP.{json,md,xlsx}`
- Logs: `data/logs/rag_system.log`
- LLM answers: `data/llm_answer_TIMESTAMP.txt` (archived in `data/archive/`)

### **System Files**
- Vector index: `data/faiss_index/faiss_index.bin`
- Metadata: `data/faiss_index/chunk_metadata.pkl`
- Document registry: `data/faiss_index/document_registry.pkl`

---

## ğŸ› ï¸ **Maintenance**

### **Clean Up Generated Files**

```bash
# Remove old test cases
del data\test_cases\*.json
del data\test_cases\*.md
del data\test_cases\*.xlsx

# Remove old LLM answers (already archived)
del data\archive\llm_answer_*.txt
```

### **Rebuild Vector Index**

```bash
# Delete existing index
del data\faiss_index\*.bin
del data\faiss_index\*.pkl

# Re-run ingestion
python src/main_enterprise.py
# Choose [I] Ingest documents
```

---

## ğŸ“ **Notes**

- **Active Virtual Environment:** `venv_313` (Python 3.13)
- **Old venv removed:** The old `venv` folder has been deleted
- **Archive folders:** Old files are in `docs/archive/`, `data/archive/`, `scripts/archive/`
- **Test scripts:** Located in `scripts/tests/` for debugging purposes only

---

## âœ… **Project Status**

- âœ… Production-ready
- âœ… Fully documented
- âœ… Clean directory structure
- âœ… Working test generation (15 test cases per run)
- âœ… Cost-optimized (~$0.001 per generation)
- âœ… Multi-format output (JSON, Markdown, Excel)

---

**Last Cleanup:** 2025-11-29
**Maintained By:** Development Team
**Status:** Active Development / Production Use
